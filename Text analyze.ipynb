{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb\n",
    "from collections import namedtuple\n",
    "\n",
    "from gensim.summarization.textcleaner import get_sentences\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "\n",
    "\n",
    "class TaggedDocument(namedtuple('TaggedDocument', 'words tags original')):\n",
    "    \"\"\" Based on gensim's TaggedDocument. \"original\" field is added. \"\"\"\n",
    "    # FIXME: Extend class to keep all methods.\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '%s(%s, %s)' % (self.__class__.__name__, self.words, self.tags)\n",
    "\n",
    "\n",
    "def read_corpus(fname):\n",
    "    with open(fname) as f:\n",
    "        text = f.read()\n",
    "        text = text.replace('\\n', '')\n",
    "        for i, sentence in enumerate(get_sentences(text)):\n",
    "            yield TaggedDocument(simple_preprocess(sentence), [i], sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus('book.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(train_corpus, vector_size=50, min_count=2, epochs=40, train_lbls=False)\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "path = get_tmpfile(\"word2vec.model\")\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: A rough sketch of the circumstances which led up to my being taken aprisoner of war are more or less indispensable.\n",
      "[1.0] A rough sketch of the circumstances which led up to my being taken aprisoner of war are more or less indispensable.\n",
      "[0.8225002884864807] My own nurse was especially attentive,and I shall be eternally grateful to her.\n",
      "[0.7567362189292908] My exemplary behaviour!\n",
      "[0.7565072774887085] Gad!\n",
      "[0.7550219297409058] Such a speech from a German secondlieutenant to a British or French senior officer was of coursedisgraceful.\n",
      "[0.7475894093513489] General Terms of Use and Redistributing Project Gutenberg-tmelectronic works1.A.\n",
      "[0.7413011193275452] Seeparagraph 1.C below.\n",
      "[0.7401611804962158] â€œMy God!\n",
      "[0.7326911091804504] If you wish to charge a fee or distribute a Project Gutenberg-tmelectronic work or group of works on different terms than are setforth in this agreement, you must obtain permission in writing fromboth the Project Gutenberg Literary Archive Foundation and MichaelHart, the owner of the Project Gutenberg-tm trademark.\n",
      "[0.7281907796859741] Mr.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Workspace/test_project/venv/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec.load(\"word2vec.model\")\n",
    "\n",
    "target_id = 0\n",
    "print('Target: {}'.format(train_corpus[target_id].original))\n",
    "\n",
    "similarity = {}\n",
    "for i, sentence in enumerate(train_corpus):\n",
    "    similarity[i] = model.docvecs.similarity(target_id, i)\n",
    "    \n",
    "sorted_similarity = sorted(similarity.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "for i, value in sorted_similarity[:10]:\n",
    "    print('[{}] {}'.format(value, train_corpus[i].original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
